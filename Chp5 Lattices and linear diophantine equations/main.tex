
\documentclass{article}

\setlength{\oddsidemargin}{0.05 in}
\setlength{\evensidemargin}{-0.05 in}
\setlength{\topmargin}{-0.6 in}
\setlength{\textwidth}{6.5 in}
\setlength{\textheight}{9.5 in}
\setlength{\headsep}{0.25 in}
\setlength{\parskip}{0.1 in}

%
% ADD PACKAGES here:
\usepackage [usenames] {color}
\definecolor {infocolor} {rgb} {0.6,0.6,0.6}
\definecolor {steel blue}{rgb}{0.274510,0.509804,0.705882}
\everymath{\color{steel blue}}
\everydisplay{\color{steel blue}}
%
\usepackage{tikz}
\usetikzlibrary{calc}

\usepackage{amsmath,amsfonts,amssymb,enumerate,graphicx}

%
% The following commands set up the lecnum (lecture number)
% counter and make various numbering schemes work relative
% to the lecture number.
%
\newcounter{lecnum}
\renewcommand{\thepage}{\thelecnum-\arabic{page}}
\renewcommand{\thesection}{\thelecnum.\arabic{section}}
\renewcommand{\theequation}{\thelecnum.\arabic{equation}}
\renewcommand{\thefigure}{\thelecnum.\arabic{figure}}
\renewcommand{\thetable}{\thelecnum.\arabic{table}}

\DeclareMathOperator{\rk}{rk}

\newcommand{\tran}{^{\mbox{\tiny $\top$}}}
\newcommand{\tleq}{^{\mbox{\tiny $\leqslant$}}}
\newcommand{\teq}{^{\mbox{\tiny $=$}}}

%
% The following macro is used to generate the header.
%
\newcommand{\lecture}[2]{
   \pagestyle{myheadings}
   \thispagestyle{plain}
   \newpage
   \setcounter{lecnum}{#1}
   \setcounter{page}{1}
   \noindent
   \begin{center}
       \vbox{\vspace{2mm}
         \hbox {\leftline{\Large LECTURE #1: \hfill}}
         \vspace{3mm}
         \hbox {\leftline{\Large #2 \hfill}}
         \vspace{4mm}
         \hrule
         \vspace{3mm}
         \hbox to 6.5in { {{\large Polyhedral Theory}  \hfill April 2013} }
         \vspace{3mm}
        }
   \end{center}
   \markboth{LECTURE #1: #2}{LECTURE #1: #2}
   \pagenumbering{arabic}
   \vspace*{4mm}
}
%
% Convention for citations is authors' initials followed by the year.
% For example, to cite a paper by Leighton and Maggs you would type
% \cite{LM89}, and to cite a paper by Strassen you would type \cite{S69}.
% (To avoid bibliography problems, for now we redefine the \cite command.)
% Also commands that create a suitable format for the reference list.
\renewcommand{\cite}[1]{[#1]}
\def\beginrefs{\begin{list}%
        {[\arabic{equation}]}{\usecounter{equation}
         \setlength{\leftmargin}{2.0truecm}\setlength{\labelsep}{0.4truecm}%
         \setlength{\labelwidth}{1.6truecm}}}
\def\endrefs{\end{list}}
\def\bibentry#1{\item[\hbox{[#1]}]}

%Use this command for a figure; it puts a figure in wherever you want it.
%usage: \fig{NUMBER}{SPACE-IN-INCHES}{CAPTION}
\newcommand{\fig}[3]{
            \vspace{#2}
        	\begin{center}
			Figure \thelecnum.#1:~#3
			\end{center}
	}
% Use these for theorems, lemmas, proofs, etc.
\newtheorem{theorem}{Theorem}[lecnum]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newenvironment{proof}{{\it Proof.}}{ \hfill $\square$}

% **** IF YOU WANT TO DEFINE ADDITIONAL MACROS FOR YOURSELF, PUT THEM HERE:

\def\R{{\mathbb R}}
\def\Q{{\mathbb Q}}
\def\Z{{\mathbb Z}}
\def\K{{\mathbb K}}

\begin{document}
%FILL IN THE RIGHT INFO.
%\lecture{**LECTURE-NUMBER**}{**DATE**}{**LECTURER**}{**SCRIBE**}
\lecture{5}{Integer lattices}
%\footnotetext{These notes are partially based on those of Nigel Mansell.}

% **** YOUR NOTES GO HERE:

% Some general latex examples and examples making use of the
% macros follow.
%**** IN GENERAL, BE BRIEF. LONG SCRIBE NOTES, NO MATTER HOW WELL WRITTEN,
%**** ARE NEVER READ BY ANYBODY.

Before we proceed to the study of integer polyhedra, we need study an important ingredient: integer lattices. Sometimes it is called geometry of numbers.

\section{Lattices}
\subsection{Definition}
A subset $\Lambda$ of $\R^n$ is called an (additive) group if
\begin{enumerate}[(i)]
\item $0\in \Lambda$;
\item if $x$, $y\in \Lambda$, then $x+y\in \Lambda$ and $-x\in \Lambda$.
\end{enumerate}
The group is said to be generated by $B=[b_1,\dots,b_k]\in \R^{n\times k}$ is
\[
\Lambda=\{\sum_{i=1}^k \lambda_i b_i~|~\lambda_1,\dots,\lambda_k\in \Z\}=\{Bx~|~x\in\Z^n\},
\]
and denoted by $\Lambda(B)$. The group is called a \emph{\textbf{lattice}} if $b_1,\dots,b_k$ are linearly independent. $B$ is called a \emph{\textbf{basis}} of $\Lambda(B)$. In particular, $\Z^n$ is the special lattice generated by standard unit vectors, i.e., $\Z^n=\Lambda(e_1,\dots,e_n)$.

\subsection{Multiple bases}
The interesting thing is that $\Z^n$ can also be generated by vectors $e_1+e_2, e_3,\dots,e_n$ (since the sum $\lambda_1 e_1+\lambda_2 e_2$, where $\lambda_1,\lambda_2\in\Z$, can be written as $\lambda_1(e_1+e_2)+(\lambda_2-\lambda_2)e_2$, and the coefficients remain integral; for the converse, we rewrite $\lambda_1(e_1+e_2)+\lambda_2 e_2$ as $\lambda_1 e_1+(\lambda_1+\lambda_2)e_2$). Thus the basis of a lattice is not unique. Furthermore, it turns out that all the bases of a given lattice are unimodular equivalent.

\section{Unimodular matrices}
A nonsingular integral matrix $U$ is \emph{\textbf{unimodular}} if $\det(U)=\pm 1$.

Following are some useful facts about unimodular matrices.
\begin{proposition}
Let $U$ be a unimodular matrix. Then
\begin{enumerate}[(a)]
\item the inverse $U^{-1}$ is also unimodular;
\item $x$ is an integral vector if and only if $Ux$ is an integral vector.
\end{enumerate}
\end{proposition}
\begin{proof}
Since $U$ is integral, all cofactors of $U$ are integers. It follows that all entries of $U^{-1}$ are also integers, as $\lvert \det(U)\rvert=1$. Finally, $UU^{-1}=I$ implies $\det(U)\det(U^{-1})=1$, hence $\lvert \det(U^{-1})\rvert=1$. This proves part (a). It is obvious that if $x$ is an integral vector, then $Ux$ is also an integral vector. The converse follows from part (a), since $x=U^{-1}(Ux)$.
\end{proof}

Now we are ready to establish the connection between different bases of the same lattice. 

\begin{theorem}
Let $B$ and $B'$ be nonsingular matrices. Then columns of $B$ and those of $B'$ generate the same lattice, i.e., $\Lambda(B)=\Lambda(B')$ if and only if $B'=BU$ for some unimodular matrix $U$ (i.e., $B^{-1}B'$ is unimodular).
\end{theorem}
\begin{proof}
cf Schrijver corollary 4.3a or Intger points in polyhedra, Shmonin, Lemma 2.
\end{proof}

(REMOVE THE FOLLOWING AS IN THE THEOREM ABOVE, WE ASUME THAT THE MATRIX IS UNIMODULAR, WHICH MEANS THAT ITS A SQUARE MATRIX. SO THE GROUP GENERATED BY B MUST BE A LATTICE!  BUT WE ACTUALLY HAVE A MORE COMMON THEOREM CF. "LATTICES AND HERMITE NORMAL FORM" BY GENNADY SHMONIN. Be cautious that in the follow theorem, we condier general form matrices of full row rank, where do not claim that the set $\Lambda(B)$ is a lattice - $\Lambda(B)$ is just the group generated by the columns of $B$, where the vectors are not necessarily linearly independent.)

\section{Hermit normal form}
The following operations on a matrix are called \emph{\textbf{elementary column operations}}:
\begin{enumerate}[(1)]
\item exchanging two columns;
\item multiplying a column by $-1$;
\item adding an integral multiply of one column to another column.
\end{enumerate}

By elementary linear algebra, it is easy to see that each elementary column operation can be achieved by multiplying a unimodular matrix from right(is actually a particular unimodular transformation). (From elementary linear algebra, it's trivial. But here we still explain it in details.) Now we explicitly specify appropriate unimodular matrices for each of the elementary column operations. ...

We say a matrix $B$ of full row rank is in \emph{\textbf{Hermite normal form}} if it has the form $B=[H~0]$, where $H$ is a nonsingular, lower triangular, nonnegative matrix, in which each row has a unique maximum entry, which is located on the main diagonal of $H$.

Since the elementary column operations are actually unimodular transformations of a matrix, the group generated by the columns of the matrix is invariant under these operations; in other words, if we had transformed the matrix into a matrix in Hermite normal form, we also proved that this group can be generated by linearly independent vectors, and therefore, is a lattice. So we have the following theorem.

\begin{theorem}[Existence of HNF]
Each rational matrix of full row rank can be brought into Hermite normal form by a series of elementary column operation.
\end{theorem}
\begin{proof}
\end{proof}

Due to unimodularity of elementary column operations, we can derive the following corollary.

\begin{corollary}
Let $B$ be a rational matrix of full row rank. Then there is a unimodular matrix $U$ such that the matrix $BU$ is in Hermite normal form.
\end{corollary}

The corollary above implies that \emph{every rational lattice has a basis in Hermite normal form}. In the following theorem, we shall see that any rational matrix of full row rank has a unique Hermite normal form.

\begin{theorem}[Uniqueness of HNF]
Let $B$ be a rational matrix of full row rank. Then $B$ has a unique Hermite normal form $[H~0]$.
\end{theorem}
\begin{proof}
cf thm 1 in "Hermite normal form: Computation and applications" by Gennady Shmonin.
\end{proof}

\section{Linear Diophantine equations}
Linear Diophantine equations are...

Hermite normal form turns out to be very useful for solving systems of linear Diophantine equations.

Let $A$ be a mtrix and $b$ a vector, and consider the problem of finding an integral vector $x$ satisfying system $Ax=b$. In fact, we may assume that $A$ has full row rank; otherwise, we may remove redundant equations from the system. Yet, we assume all input data to be rational. We can find a unimodular matrix $U$ such that $[H|0]=AU$ is a matrix in Hermite normal form. Now we can apply a standard trick to transform a system of linear equations into a more suitable from: $Ax=b$ is equivalent to $(AU)(U^{-1}x)=b$, and therefore, $[H|0]z=b$, where $Z=U^{-1}x$ is integral if and only if $x$ is integral. We can observe that the components corresponding to zeros in Hermite normal form may take arbitrary values, while feasibility of the system $[H|0]z=b$, and therefore, of $Ax=b$, depends only on whether the vector $H^{-1}b$ is integral. Now we can derive the following condition for a system of linear Diophantine equations to have a solution.

\begin{theorem}[Integer analogue of Farkas' Lemma]
Let $A$ be a rational matrix and let $b$ be a rational column vector. Then the system $Ax=b$ has an integral solution $x$, if and only if $y^T b$ is an integer for each rational row vector $y$ for which $y^T A$ is integral.
\end{theorem}

\section{Polynomial algorithm for Hermite normal form}

\section{Algorithm for linear Diophantine equations}

\section*{References}
\beginrefs
\bibentry{CW87}{\sc Gennady Shmonin},
``Lattices and Hermite normal form'' and ``Hermite normal form: Computation and applications'', 
{\it Integer Points in Polyhedra}.
\endrefs

% **** THIS ENDS THE EXAMPLES. DON'T DELETE THE FOLLOWING LINE:

\end{document}









